{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"11\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\" # export OPENBLAS_NUM_THREADS=4 \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"11\" # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"8\" # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"11\" # export NUMEXPR_NUM_THREADS=6\n",
    "os.environ[\"NUMBA_CACHE_DIR\"]='/tmp/numba_cache'\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how to prepare input of multi-omics data for scVAEIT.\n",
    "To begin with, we use a simple example with toy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "We first illustrate the procedure of preparing input data for scVAEIT. \n",
    "Consider the following example, where we have 2 datasets, each with 2 modalities measured.\n",
    "\n",
    "Dataset | RNA | ADT | ATAC\n",
    "---|---|---|---\n",
    "1 | √ | √ | \n",
    "2 | √ |  | √\n",
    "\n",
    "\n",
    "We will use similar data structure as `annData` to demonstrate how to prepare input data for scVAEIT.\n",
    "\n",
    "### Raw data\n",
    "#### Counts\n",
    "The counts can be represented as a list of tuples, where each tuple contains the count matrix for each modality. For example, the input data can be represented as:\n",
    "```python\n",
    "[\n",
    "    (dat1_count_rna, dat1_count_adt, None)\n",
    "    (dat2_count_rna, None, dat2_count_atac)\n",
    "]\n",
    "```\n",
    "Each of the variable is a numpy array or `None`.\n",
    "\n",
    "#### Features\n",
    "\n",
    "The feature names used to align different datasets can be represented as a list of tuples, where each tuple contains the feature names for each modality. For example, the feature names can be represented as:\n",
    "```python\n",
    "[\n",
    "    (dat1_var_rna, dat1_var_adt, None)\n",
    "    (dat2_var_rna, None, dat2_var_atac)\n",
    "]\n",
    "```\n",
    "Each of the variable can be either a dataframe or a numpy array, or `None`.\n",
    "\n",
    "#### Metadata\n",
    "The metadata can also be represented by a list of arrays, where each array contains the metadata for each modality. For example, the metadata can be represented as:\n",
    "```python\n",
    "[\n",
    "    dat1_obs,\n",
    "    dat2_obs\n",
    "]\n",
    "```\n",
    "\n",
    "Each of the variable can be either a dataframe or a numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy examples\n",
    "n1 = 2; p1 = [2, 2, 0]\n",
    "dat1_count_rna, dat1_count_adt, dat1_count_atac = np.ones((n1, 2)), np.ones((n1, 2)), None\n",
    "dat1_var_rna, dat1_var_adt, dat1_var_atac = np.array(['gene1', 'gene2']), np.array(['adt1', 'adt2']), None\n",
    "dat1_obs = pd.DataFrame({'covariate': [1, 2], 'dataset_id': [0, 0]})\n",
    "\n",
    "n2 = 3; p2 = [3, 0, 3]\n",
    "dat2_count_rna, dat2_count_adt, dat2_count_atac = 2*np.ones((n2, 3)), None, 2*np.ones((n2, 3))\n",
    "dat2_var_rna, dat2_var_adt, dat2_var_atac = np.array(['gene1', 'gene2', 'gene3']), None, np.array(['atac1', 'atac2', 'atac3'])\n",
    "dat2_obs = pd.DataFrame({'covariate': [1, 2, 3], 'dataset_id': [1, 1, 1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical concatenation of single modality of multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "def vertical_concat(\n",
    "    counts, vars, obs, compact_mask=False\n",
    "    ):\n",
    "    '''\n",
    "    Concatenate multiple datasets of one modality for mosaic integration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : list\n",
    "        A list of counts from different datasets each of shape (n_i, p_i), None if missing.\n",
    "    vars : list\n",
    "        A list of pandas.Dataframe or numpy.array, each of shape (p_i, ), None if missing\n",
    "        Variables from different datasets used to align across datasets.\n",
    "    obs : list\n",
    "        A list of pandas.Dataframe or numpy.array, each of shape (n_i, c), where c is the number of covariates/batches to be adjust.\n",
    "        The covariates/batches from different datasets, the last column should be the dataset id.\n",
    "        The measurements should be the same across different datasets.\n",
    "    compact_mask : bool\n",
    "        If True, the mask is of shape (N, p) where N is the number of datasets and p=sum_i p_i is the number of features; \n",
    "        otherwise it is a matrix of shape (n, p), where n=sum_i n_i is the number of samples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : np.ndarray\n",
    "        The concatenated data matrix.\n",
    "    batches : np.ndarray\n",
    "        The covariates for each cell.\n",
    "    masks : tf.Tensor\n",
    "        The masks for missing pattern.\n",
    "    '''\n",
    "    n_datasets = len(counts)\n",
    "\n",
    "    # Check the input data\n",
    "    # and determine the total number of unique features\n",
    "    total_features = 0\n",
    "    features = []\n",
    "    for i in range(n_datasets):\n",
    "        if isinstance(obs[i], pd.DataFrame):\n",
    "            obs[i] = obs[i].values\n",
    "        elif not isinstance(obs[i], np.ndarray):\n",
    "            raise ValueError(f\"obs[{i}] must be a DataFrame or numpy array\")\n",
    "        if obs[i].ndim != 2:\n",
    "            obs[i] = obs[i][:,None]            \n",
    "\n",
    "        if isinstance(vars[i], pd.DataFrame):\n",
    "            vars[i] = np.array(vars[i].columns)\n",
    "        elif vars[i] is None:\n",
    "            continue\n",
    "        elif not isinstance(vars[i], np.ndarray):\n",
    "            raise ValueError(f\"vars[{i}] must be a DataFrame or numpy array\")\n",
    "        features.append(vars[i])    \n",
    "    \n",
    "    features = reduce(np.union1d, *features)\n",
    "    total_features = len(features)\n",
    "    print('Total number of features:', total_features)\n",
    "\n",
    "    concatenated_data = []\n",
    "    concatenated_batches = []\n",
    "    concatenated_masks = []\n",
    "\n",
    "    print('Concatenate {} datasets...'.format(n_datasets))\n",
    "    for i in tqdm(range(n_datasets)):\n",
    "        data = np.zeros((obs[i].shape[0], total_features), dtype=np.float32)\n",
    "        if compact_mask:\n",
    "            mask = -np.ones((1, total_features), dtype=np.float32)\n",
    "        else:\n",
    "            mask = -np.ones((obs[i].shape[0], total_features), dtype=np.float32)\n",
    "        if counts[i] is not None:\n",
    "            id_obs_features = np.where(np.isin(vars[i], features))[0]    \n",
    "        \n",
    "            data[:,id_obs_features] = counts[i]\n",
    "            mask[:,id_obs_features] = 0\n",
    "        \n",
    "        concatenated_data.append(data)\n",
    "        concatenated_batches.append(obs[i])\n",
    "        concatenated_masks.append(mask)\n",
    "    \n",
    "    data = np.vstack(concatenated_data)\n",
    "    batches = np.vstack(concatenated_batches)\n",
    "    masks = np.vstack(concatenated_masks)\n",
    "\n",
    "    return data, batches, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 3\n",
      "Concatenate 2 datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2384.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      " [[1. 1. 0.]\n",
      " [1. 1. 0.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n",
      "Batches:\n",
      " [[1 0]\n",
      " [2 0]\n",
      " [1 1]\n",
      " [2 1]\n",
      " [3 1]]\n",
      "Masks:\n",
      " [[ 0.  0. -1.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "data_rna, batches, masks_rna = vertical_concat([dat1_count_rna, dat2_count_rna], [dat1_var_rna, dat2_var_rna], [dat1_obs, dat2_obs])\n",
    "\n",
    "# Print results\n",
    "print(\"Data:\\n\", data_rna)\n",
    "print(\"Batches:\\n\", batches)\n",
    "print(\"Masks:\\n\", masks_rna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can concatenate the ADT and ATAC modalities, separately.\n",
    "Because `batches` would be the same for every modality, we simply ignore the output for it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 2\n",
      "Concatenate 2 datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12985.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 3\n",
      "Concatenate 2 datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 14716.86it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 14716.86it/s]\n"
     ]
    }
   ],
   "source": [
    "data_adt, _, masks_adt = vertical_concat([dat1_count_adt, dat2_count_adt], [dat1_var_adt, dat2_var_adt], [dat1_obs, dat2_obs])\n",
    "data_atac, _, masks_atac = vertical_concat([dat1_count_atac, dat2_count_atac], [dat1_var_atac, dat2_var_atac], [dat1_obs, dat2_obs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal concatenation of multimodalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_concat(\n",
    "    vertical_concated_data, vertical_concated_masks\n",
    "    ):\n",
    "    '''\n",
    "    Concatenate multiple modalities of datasets for mosaic integration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vertical_concated_data : list\n",
    "        A list of counts from different modalities.\n",
    "    vertical_concated_masks : list\n",
    "        A list of masks from different modalities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : np.ndarray\n",
    "        The concatenated data matrix.\n",
    "    masks : tf.Tensor\n",
    "        The masks for missing pattern.\n",
    "    '''\n",
    "\n",
    "    n_modalities = len(vertical_concated_data)\n",
    "\n",
    "    # Initialize lists to store concatenated results\n",
    "    concatenated_data = []\n",
    "    concatenated_masks = []\n",
    "\n",
    "    # Determine the total number of features\n",
    "    dim_block = np.array([data.shape[1] for data in vertical_concated_data])\n",
    "\n",
    "    print('Concatenate {} modalities...'.format(n_modalities))\n",
    "    for i in tqdm(range(n_modalities)):\n",
    "        data = vertical_concated_data[i]\n",
    "        masks = vertical_concated_masks[i]\n",
    "\n",
    "        concatenated_data.append(data)\n",
    "        concatenated_masks.append(masks)\n",
    "\n",
    "    # Concatenate data, batches, and masks horizontally\n",
    "    data = np.hstack(concatenated_data)\n",
    "    masks = np.hstack(concatenated_masks)\n",
    "\n",
    "    return data, masks, dim_block\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenate 3 modalities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 62291.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      " [[1. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [2. 2. 2. 0. 0. 2. 2. 2.]\n",
      " [2. 2. 2. 0. 0. 2. 2. 2.]\n",
      " [2. 2. 2. 0. 0. 2. 2. 2.]]\n",
      "Masks:\n",
      " [[ 0.  0. -1.  0.  0. -1. -1. -1.]\n",
      " [ 0.  0. -1.  0.  0. -1. -1. -1.]\n",
      " [ 0.  0.  0. -1. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1. -1.  0.  0.  0.]]\n",
      "Dim of modalities: [3 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "data, masks, dim_block = horizontal_concat([data_rna, data_adt, data_atac], [masks_rna, masks_adt, masks_atac])\n",
    "\n",
    "# Print results\n",
    "print(\"Data:\\n\", data)\n",
    "print(\"Masks:\\n\", masks)\n",
    "print('Dim of modalities:', dim_block)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
